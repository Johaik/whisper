# ğŸ“ Whisper Call Transcription Pipeline

A production-ready call recording transcription system that automatically processes audio files, transcribes Hebrew speech, identifies speakers, and provides rich analyticsâ€”all accessible via a REST API.

<p align="center">
  <img src="https://img.shields.io/badge/Hebrew-Optimized-blue?style=flat-square" alt="Hebrew Optimized"/>
  <img src="https://img.shields.io/badge/Powered%20by-ivrit--ai-orange?style=flat-square" alt="Powered by ivrit-ai"/>
  <img src="https://img.shields.io/badge/FastAPI-009688?style=flat-square&logo=fastapi&logoColor=white" alt="FastAPI"/>
  <img src="https://img.shields.io/badge/Celery-37814A?style=flat-square&logo=celery&logoColor=white" alt="Celery"/>
  <img src="https://img.shields.io/badge/Docker-2496ED?style=flat-square&logo=docker&logoColor=white" alt="Docker"/>
</p>

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ™ï¸ **Hebrew Transcription** | Uses [ivrit-ai](https://huggingface.co/ivrit-ai) models fine-tuned on 295+ hours of Hebrew speech |
| ğŸ‘¥ **Speaker Diarization** | Identifies who spoke when using [pyannote.audio](https://github.com/pyannote/pyannote-audio) |
| ğŸ“Š **Call Analytics** | Computes talk time, silence ratio, speaker turns, and more |
| ğŸ“ **Auto-Discovery** | Watches a folder and automatically processes new recordings |
| ğŸ“‡ **Caller ID** | Looks up caller names from Google Contacts via phone number |
| ğŸ”„ **Async Processing** | Background workers handle transcription without blocking |
| ğŸŒ **REST API** | Full-featured API for ingestion, querying, and reprocessing |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Folder        â”‚     â”‚   FastAPI       â”‚     â”‚   PostgreSQL    â”‚
â”‚   Watcher       â”‚â”€â”€â”€â”€â–¶â”‚   API           â”‚â”€â”€â”€â”€â–¶â”‚   Database      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚
        â”‚                       â”‚
        â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Redis         â”‚â—€â”€â”€â”€â”€â”‚   Celery        â”‚
â”‚   Queue         â”‚     â”‚   Worker        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼              â–¼              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Whisper   â”‚  â”‚ Pyannote  â”‚  â”‚ Google    â”‚
        â”‚ Transcibe â”‚  â”‚ Diarize   â”‚  â”‚ Contacts  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

- **Folder Watcher** â€” Polls a directory for new audio files, queues them for processing
- **FastAPI API** â€” REST endpoints for ingestion, recording list, details, and health checks
- **Celery Worker** â€” Processes recordings asynchronously (transcription, diarization, analytics)
- **PostgreSQL** â€” Stores recordings, transcripts, and enrichment data
- **Redis** â€” Message broker for Celery task queue

---

## ğŸ“‹ Processing Pipeline

When a new recording is detected, it goes through these steps:

```
1. ğŸ“‚ DISCOVERED    â†’ File found in watch folder
2. ğŸ“ PARSE         â†’ Extract phone number & timestamp from filename
3. ğŸ” METADATA      â†’ Extract audio properties (duration, codec, sample rate)
4. ğŸ¤ TRANSCRIBE    â†’ Convert speech to text using Whisper
5. ğŸ‘¥ DIARIZE       â†’ Identify different speakers (optional)
6. ğŸ“Š ANALYTICS     â†’ Compute talk time, silence, speaker turns
7. ğŸ“‡ CONTACTS      â†’ Look up caller name from Google Contacts (optional)
8. âœ… DONE          â†’ Store results in database
```

### Filename Parsing

The system automatically parses call recording filenames to extract metadata:

```
Call recording +15551234567_200605_114902.m4a
              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â””â”€â”€â”¬â”€â”€â”˜â””â”€â”€â”¬â”€â”€â”€â”˜
                Phone     Date    Time
              Number    YYMMDD  HHMMSS
```

---

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- HuggingFace token (for speaker diarization)
- Google API credentials (optional, for caller name lookup)

### 1. Clone and Configure

```bash
# Clone the repository
git clone <your-repo-url>
cd whisper

# Create environment file
cat > .env << EOF
API_TOKEN=your-secure-api-token
HUGGINGFACE_TOKEN=hf_your_huggingface_token
DIARIZATION_ENABLED=true
EOF
```

### 2. Start the Services

```bash
# Start all services
docker-compose up -d

# Run database migrations
docker-compose run --rm migrate

# Check service health
curl http://localhost:8000/api/v1/health
```

### 3. Add Recordings

Place your call recordings in the `Calls/` folder. The watcher will automatically detect and process them.

```bash
# Or trigger manual ingestion via API
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "Authorization: Bearer your-secure-api-token" \
  -H "Content-Type: application/json"
```

---

## ğŸ”Œ API Reference

### Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/v1/health` | Service health check |
| `POST` | `/api/v1/ingest` | Scan folder and queue recordings |
| `GET` | `/api/v1/recordings` | List all recordings (paginated) |
| `GET` | `/api/v1/recordings/{id}` | Get recording details with transcript |
| `POST` | `/api/v1/recordings/{id}/reprocess` | Requeue a recording for processing |

### Authentication

All endpoints (except `/health`) require a Bearer token:

```bash
curl -H "Authorization: Bearer your-api-token" http://localhost:8000/api/v1/recordings
```

### Example: Get Recording Details

```bash
curl -H "Authorization: Bearer your-api-token" \
  "http://localhost:8000/api/v1/recordings/550e8400-e29b-41d4-a716-446655440000"
```

Response:
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "file_name": "Call recording +972521234567_230115_103045.m4a",
  "status": "done",
  "duration_sec": 185.5,
  "phone_number": "+972521234567",
  "caller_name": "John Doe",
  "call_datetime": "2023-01-15T10:30:45",
  "transcript": {
    "text": "×©×œ×•×, ××” ×©×œ×•××š? ×‘×¡×“×¨ ×’××•×¨, ×ª×•×“×”...",
    "language": "he",
    "language_probability": 0.98,
    "segments": [
      {"start": 0.0, "end": 2.5, "text": "×©×œ×•×, ××” ×©×œ×•××š?", "speaker": "SPEAKER_00"},
      {"start": 2.8, "end": 5.1, "text": "×‘×¡×“×¨ ×’××•×¨, ×ª×•×“×”", "speaker": "SPEAKER_01"}
    ]
  },
  "enrichment": {
    "speaker_count": 2,
    "total_speech_time": 165.2,
    "total_silence_time": 20.3,
    "talk_time_ratio": 0.89,
    "speaker_turns": 24
  }
}
```

### Interactive API Docs

Visit **http://localhost:8000/docs** for Swagger UI documentation.

---

## âš™ï¸ Configuration

Configure via environment variables or `.env` file:

### Core Settings

| Variable | Default | Description |
|----------|---------|-------------|
| `API_TOKEN` | `dev-token-change-me` | API authentication token |
| `DATABASE_URL` | `postgresql+asyncpg://...` | PostgreSQL connection string |
| `REDIS_URL` | `redis://localhost:6379/0` | Redis connection string |
| `CALLS_DIR` | `/data/calls` | Directory to watch for recordings |

### Transcription Settings

| Variable | Default | Description |
|----------|---------|-------------|
| `MODEL_NAME` | `ivrit-ai/whisper-large-v3-turbo-ct2` | Whisper model to use |
| `DEVICE` | `cpu` | Device (`cpu` or `cuda`) |
| `COMPUTE_TYPE` | `int8` | Precision (`int8`, `float16`, `float32`) |
| `BEAM_SIZE` | `5` | Beam search size (higher = more accurate) |
| `VAD_FILTER` | `true` | Voice Activity Detection filtering |

### Diarization Settings

| Variable | Default | Description |
|----------|---------|-------------|
| `DIARIZATION_ENABLED` | `true` | Enable speaker diarization |
| `HUGGINGFACE_TOKEN` | â€” | Required for pyannote.audio models |

### Google Contacts (Optional)

| Variable | Description |
|----------|-------------|
| `GOOGLE_CLIENT_ID` | OAuth 2.0 client ID |
| `GOOGLE_CLIENT_SECRET` | OAuth 2.0 client secret |
| `GOOGLE_REFRESH_TOKEN` | OAuth 2.0 refresh token |

### Watcher Settings

| Variable | Default | Description |
|----------|---------|-------------|
| `WATCHER_POLL_INTERVAL` | `30` | Seconds between folder scans |
| `WATCHER_STABLE_SECONDS` | `10` | File must be stable for this long before processing |

---

## ğŸ§ª Development

### Local Setup

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Start infrastructure
docker-compose up -d postgres redis

# Run migrations
alembic upgrade head

# Start API server
uvicorn app.main:app --reload

# Start worker (in another terminal)
celery -A app.worker.celery_app worker --loglevel=info

# Start watcher (in another terminal)
python -m app.watcher.folder_watcher
```

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test categories
pytest tests/unit/          # Unit tests only
pytest tests/integration/   # Integration tests only
```

### Project Structure

```
whisper/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                 # FastAPI routes and schemas
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ db/                  # Database models and sessions
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ session.py
â”‚   â”‚   â””â”€â”€ migrations/      # Alembic migrations
â”‚   â”œâ”€â”€ processors/          # Audio processing modules
â”‚   â”‚   â”œâ”€â”€ transcribe.py    # Whisper transcription
â”‚   â”‚   â”œâ”€â”€ diarize.py       # Speaker diarization
â”‚   â”‚   â”œâ”€â”€ analytics.py     # Call analytics
â”‚   â”‚   â”œâ”€â”€ metadata.py      # Audio metadata extraction
â”‚   â”‚   â””â”€â”€ filename_parser.py
â”‚   â”œâ”€â”€ services/            # External integrations
â”‚   â”‚   â””â”€â”€ google_contacts.py
â”‚   â”œâ”€â”€ watcher/             # Folder monitoring
â”‚   â”‚   â””â”€â”€ folder_watcher.py
â”‚   â”œâ”€â”€ worker/              # Celery tasks
â”‚   â”‚   â”œâ”€â”€ celery_app.py
â”‚   â”‚   â””â”€â”€ tasks.py
â”‚   â”œâ”€â”€ auth.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ tests/                   # Test suite
â”œâ”€â”€ Calls/                   # Default recordings folder
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Standalone Transcription

For quick one-off transcription without the full pipeline:

```bash
# Activate the virtual environment
source venv/bin/activate

# Using ivrit-ai model (recommended for Hebrew)
python transcribe_hebrew.py audio.mp3 --ivrit

# With timestamps
python transcribe_hebrew.py audio.mp3 --ivrit --timestamps

# Save to file
python transcribe_hebrew.py audio.mp3 --ivrit --output result.txt

# Higher accuracy (slower)
python transcribe_hebrew.py audio.mp3 --ivrit --beam-size 10
```

---

## ğŸ“Š Model Comparison

### Hebrew-Optimized Models (Recommended)

| Model | Speed | Accuracy | Notes |
|-------|-------|----------|-------|
| `ivrit-ai/whisper-large-v3-turbo-ct2` | âš¡ Fast | â˜…â˜…â˜…â˜…â˜… | Default, fine-tuned on 295+ hrs Hebrew |
| `ivrit-ai/whisper-large-v3-ct2` | ğŸ¢ Slow | â˜…â˜…â˜…â˜…â˜… | Maximum accuracy |

### Standard Whisper Models

| Model | VRAM | Speed | Hebrew Accuracy |
|-------|------|-------|-----------------|
| `tiny` | ~1GB | âš¡âš¡âš¡ | â˜…â˜†â˜†â˜†â˜† |
| `base` | ~1GB | âš¡âš¡âš¡ | â˜…â˜…â˜†â˜†â˜† |
| `small` | ~2GB | âš¡âš¡ | â˜…â˜…â˜…â˜†â˜† |
| `medium` | ~5GB | âš¡ | â˜…â˜…â˜…â˜…â˜† |
| `large-v3` | ~10GB | ğŸ¢ | â˜…â˜…â˜…â˜…â˜† |

---

## ğŸ™ Credits

- [OpenAI Whisper](https://github.com/openai/whisper) â€” Base speech recognition
- [ivrit.ai](https://huggingface.co/ivrit-ai) â€” Hebrew fine-tuned models
- [faster-whisper](https://github.com/SYSTRAN/faster-whisper) â€” CTranslate2 inference
- [pyannote.audio](https://github.com/pyannote/pyannote-audio) â€” Speaker diarization

---

---

## ğŸ“š Documentation

Detailed documentation is available in the [`docs/`](docs/) folder:

| Document | Description |
|----------|-------------|
| [Deployment Guide](docs/deployment.md) | Deploy from Mac to Windows |
| [Makefile Reference](docs/makefile.md) | All available make commands |
| [Architecture](docs/architecture.md) | System components and data flow |
| [Configuration](docs/configuration.md) | Environment variables reference |
| [Security](docs/security.md) | Security considerations |
| [Google Drive Integration](docs/google-drive.md) | Process files from Google Drive |

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.
