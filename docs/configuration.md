# Configuration Reference

All configuration is done via environment variables, either in `.env` file or directly.

## Environment Files

### Local Development (Mac)
Create `.env` in project root:
```bash
API_TOKEN=dev-token-change-me
DIARIZATION_ENABLED=false
```

### Windows Deployment
The `.env` file is created automatically by `make deploy` at `C:\app\.env`.

## Configuration Categories

### Core Settings

| Variable | Default | Description |
|----------|---------|-------------|
| `API_TOKEN` | `dev-token-change-me` | API authentication token |
| `DATABASE_URL` | `postgresql+asyncpg://whisper:whisper@postgres:5432/whisper` | Async PostgreSQL connection |
| `DATABASE_URL_SYNC` | `postgresql://whisper:whisper@postgres:5432/whisper` | Sync PostgreSQL connection |
| `REDIS_URL` | `redis://redis:6379/0` | Redis connection string |
| `CALLS_DIR` | `/data/calls` | Directory to watch for recordings |
| `OUTPUT_DIR` | `/data/outputs` | Directory for transcription results |

### Transcription Settings

| Variable | Default | Description |
|----------|---------|-------------|
| `MODEL_NAME` | `ivrit-ai/whisper-large-v3-turbo-ct2` | Whisper model to use |
| `DEVICE` | `cpu` | Device: `cpu` or `cuda` |
| `COMPUTE_TYPE` | `float32` | Precision: `int8`, `float16`, `float32` |
| `BEAM_SIZE` | `10` | Beam search size (1-10, higher = more accurate) |
| `VAD_FILTER` | `true` | Enable Voice Activity Detection |

#### Model Options

| Model | Speed | Accuracy | Size |
|-------|-------|----------|------|
| `ivrit-ai/whisper-large-v3-turbo-ct2` | Fast | Excellent | ~1.5 GB |
| `ivrit-ai/whisper-large-v3-ct2` | Slow | Maximum | ~3 GB |
| `large-v3` | Slow | Good | ~3 GB |
| `medium` | Medium | Good | ~1.5 GB |
| `small` | Fast | Fair | ~500 MB |

### Diarization Settings

| Variable | Default | Description |
|----------|---------|-------------|
| `DIARIZATION_ENABLED` | `false` | Enable speaker diarization |
| `HUGGINGFACE_TOKEN` | â€” | Required for pyannote.audio models |

**Note:** Diarization requires a HuggingFace token with access to pyannote models.
Get token at: https://huggingface.co/settings/tokens

### Google Contacts (Optional)

| Variable | Description |
|----------|-------------|
| `GOOGLE_CLIENT_ID` | OAuth 2.0 client ID |
| `GOOGLE_CLIENT_SECRET` | OAuth 2.0 client secret |
| `GOOGLE_REFRESH_TOKEN` | OAuth 2.0 refresh token |

Used to look up caller names from Google Contacts based on phone number.

### Watcher Settings

| Variable | Default | Description |
|----------|---------|-------------|
| `WATCHER_POLL_INTERVAL` | `30` | Seconds between folder scans |
| `WATCHER_STABLE_SECONDS` | `10` | File must be stable for this long |

## Ansible Configuration

### Inventory (`ansible/inventory.ini`)

```ini
[windows]
winhost ansible_host=192.168.50.9

[windows:vars]
ansible_user=your_username
ansible_password=your_password
ansible_connection=winrm
ansible_winrm_transport=ntlm
ansible_port=5985
ansible_winrm_server_cert_validation=ignore
```

### Group Variables (`ansible/group_vars/all.yml`)

```yaml
# GitHub Container Registry settings
ghcr_registry: "ghcr.io"
ghcr_username: "your_github_username"

# Token loaded from file (git-ignored)
ghcr_token: "{{ lookup('file', playbook_dir + '/.ghcr_token') | trim }}"

# Image names
images:
  api: "{{ ghcr_registry }}/{{ ghcr_username }}/whisper-api"
  worker: "{{ ghcr_registry }}/{{ ghcr_username }}/whisper-worker"
  watcher: "{{ ghcr_registry }}/{{ ghcr_username }}/whisper-watcher"

# Image tag
image_tag: "latest"

# Windows deployment path
win_app_dir: "C:\\app"
```

### GitHub Token (`ansible/.ghcr_token`)

Store your GitHub Personal Access Token here (file is git-ignored):

```bash
echo "ghp_xxxxxxxxxxxx" > ansible/.ghcr_token
```

Required scopes:
- `read:packages` - Pull images
- `write:packages` - Push images

## Docker Compose Override

### Local Development (`docker-compose.override.yml`)

```yaml
services:
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    image: whisper-api:local
  # ... similar for worker, watcher
```

### Windows Production (generated by deploy)

```yaml
services:
  postgres:
    volumes:
      - C:\app\postgres-data:/var/lib/postgresql/data
  redis:
    volumes:
      - C:\app\redis-data:/data
  api:
    volumes:
      - C:\app\Calls:/data/calls:ro
      - C:\app\outputs:/data/outputs
  # ... etc
```

## Compute Type Guide

| Type | Memory | Speed | Accuracy | Use Case |
|------|--------|-------|----------|----------|
| `int8` | Low | Fast | Good | Limited RAM, quick processing |
| `float16` | Medium | Medium | Better | GPU with FP16 support |
| `float32` | High | Slow | Best | Maximum accuracy, plenty of RAM |

## Recommended Configurations

### Low-Resource Machine (8GB RAM)

```bash
MODEL_NAME=ivrit-ai/whisper-large-v3-turbo-ct2
COMPUTE_TYPE=int8
BEAM_SIZE=5
DIARIZATION_ENABLED=false
```

### Standard Machine (16GB RAM)

```bash
MODEL_NAME=ivrit-ai/whisper-large-v3-turbo-ct2
COMPUTE_TYPE=float32
BEAM_SIZE=10
DIARIZATION_ENABLED=true
```

### High-Accuracy (32GB+ RAM)

```bash
MODEL_NAME=ivrit-ai/whisper-large-v3-ct2
COMPUTE_TYPE=float32
BEAM_SIZE=10
DIARIZATION_ENABLED=true
```
